
---
title: "Design and analysis template MCP-Mod for binary data"
output: rmarkdown::html_vignette
bibliography: refs.bib
vignette: >
  %\VignetteIndexEntry{Design and analysis template MCP-Mod for binary data}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, cache = FALSE)
```

Illustrate points to consider for binary data for planning and
analysis stage (See also pitfalls pdf document)

## Background

Assume a dose-finding study is planned for an hypothetical investigational treatment in 
atopic dermatitis, for the binary endpoint Investigator's Global Assessment (IGA). 
The treatment is tested with doses 0, 0.5, 1.5, 2.5, 4. It is assumed 
the response rate for placebo will be around 10%, while the response rate for the
top dose may be 35%.
This is an example where the generalized MCP-Mod approach can be applied. 
That is dose-response testing and estimation will be performed on the 
logit scale.

## Candidate set

Assume the following candidate set is desired to be used (on logit scale).

```{r}
library(data.table)
library(ggplot2)
library(DoseFinding)
logit <- function(p)
  log(p/(1-p))
inv_logit <- function(y)
  1/(1+exp(-y))
doses <- c(0, 0.5, 1.5, 2.5, 4)
## define candidate models
mods <- Mods(emax = c(0.25, 1), 
             sigEmax = rbind(c(1, 3), c(2.5, 4)),
             betaMod = c(1.1, 1.1),
             placEff = logit(0.1), maxEff = logit(0.35)-logit(0.1),
         doses = doses)
## graphical display of candidate shapes
plot(mods)
## graphical display on probability scale
sq <- seq(0,4,by=0.05)
rsp <- getResp(mods, doses=sq)
modnam <- factor(colnames(rsp), levels=colnames(rsp))
pdat <- data.table(resp = inv_logit(c(rsp)),
                   mod = rep(modnam, each = 81),
                   dose = rep(sq, 5))
ggplot(pdat, aes(dose, resp))+
  geom_line(lwd=I(1.2))+
  facet_wrap(~mod)+
  scale_y_continuous(breaks = seq(0,0.45,by=0.1),limits=c(0,0.45))
```



## Analysis
Generate some example data according to setting above

```{r}
set.seed(1)
doseV <- rep(doses, each = 60)
N <- length(doseV)
## generate covariates
x1 <- rnorm(N, 0, 1)
x2 <- factor(sample(c("A", "B"), N, replace=TRUE, prob=c(0.75, 0.25)))
## assume approximately 10% placebo and 35% asymptotic response
prob <- inv_logit(emax(doseV, -2.2, 1.6, 0.5) + 0.3*x1 + 0.3*(x2=="B"))
y <- rbinom(N, 1, prob)
dat <- data.table(y=y, dose=doseV, x1=x1, x2=x2)
```

## Analysis considerations (unadjusted analysis)

Same as outlined in Pinheiro et al 2014
Perform MCP-Mod test on logit scale (contrasts applied to logits).

```{r}
## First assume covariates had not been used in the analysis (not recommended!)
fit <- glm(y~factor(dose)-1, data=dat, family=binomial)
S <- vcov(fit)
est <- coef(fit)
MCTtest(doses, est, S=S, models=mods, type="general")
```
Dose-response modelling proceeds as

```{r}
nSim <- 1000
sims <- rmvnorm(nSim, est, S)
## now actual model fitting and selection of best model for all bootstraps
bnds <- defBnds(max(doses)) ## boundaries assumed for model fitting (force convergence)
dsq <- seq(0,4,length=51)
pred <- matrix(nrow=nSim, ncol=51) ## will contain dr-model predictions 
fit <- vector("list", 3)
for(i in 1:nSim){
  fit[[1]] <- fitMod(doses, sims[i,], model="emax", S=S,
                     type="general", bnds=bnds$emax)
  fit[[2]] <- fitMod(doses, sims[i,], model="sigEmax", S=S,
                     type="general", bnds=bnds$sigEmax)
  fit[[3]] <- fitMod(doses, sims[i,], model="betaMod", S=S,
                     type="general", bnds=bnds$betaMod)
  ind <- which.min(sapply(fit, gAIC)) ## choose best model according to AIC
  pred[i,] <- predict(fit[[ind]], doseSeq=dsq, predType="ls-means")
}
qq <- apply(pred, 2, function(x) quantile(x, c(0.025,0.25,0.5,0.75,0.975)))
pp <- inv_logit(qq)

pdat <- data.table(dsq = dsq, pred = pp[3,],
                   low1 = pp[2,], high1 = pp[4,],
                   low2 = pp[1,], high2 = pp[5,])
qq <- qnorm(0.975)
pdat2 <- data.table(dose = doses, est=inv_logit(est),
                    LB = inv_logit(est - qq*sqrt(diag(S))),
                    UB = inv_logit(est + qq*sqrt(diag(S))))

qplot(dsq, pred, data=pdat, geom="line", xlab = "Dose",
      ylab="Response Probability")+
  geom_point(aes(dose, y=est), data=pdat2, alpha=0.5)+
  geom_errorbar(aes(x=dose, y=est, ymin = LB, ymax = UB),
                 data=pdat2, width=0,alpha=0.5)+
  geom_ribbon(aes(ymin = low1, ymax = high1), alpha=0.2)+
  geom_ribbon(aes(ymin = low2, ymax = high2), alpha=0.2)+
  scale_y_continuous(breaks = seq(0,1,by=0.05))+
  theme_bw()
```

## Adjusted analysis

In many situations there are important prognostic covariates (main effects) to adjust for in the analysis. The code below illustrates, how this can be achieved. Ludger please check this makes sense...

```{r}
fit <- glm(y~factor(dose)+x1+x2, data=dat, family=binomial)
## predict every patient under *every* dose
pdat <- data.table(dose = rep(doses, each = nrow(dat)),
                   x1 = rep(x1, length(doses)),
                   x2 = rep(x2, length(doses)))
## calculate the average response probability per dose (averaged over all patients)
## return result on logit scale
get_pred <- function(X, par, doses){
  p <- inv_logit(X%*%par)
  logit(tapply(p, doses, mean))
}
X <- model.matrix(~factor(dose)+x1+x2, data=pdat)
est <- get_pred(X, coef(fit), pdat$dose)
## now approximate variance estimate based on simulation
sims <- rmvnorm(1000, coef(fit), vcov(fit))
preds <- matrix(nrow=1000, ncol=length(doses))
for(i in 1:1000){
  preds[i,] <- get_pred(X, sims[i,], pdat$dose)
}
S <- cov(preds)

## perform multiple contrast test
MCTtest(doses, est, S=S, type = "general", models=mods)
```

Dose-response modelling proceeds in the same way as before but now on the adjusted estimates.

```{r}
nSim <- 1000
sims <- rmvnorm(nSim, est, S)
## now actual model fitting and selection of best model for all bootstraps
bnds <- defBnds(max(doses)) ## boundaries assumed for model fitting (force convergence)
dsq <- seq(0,4,length=51)
pred <- matrix(nrow=nSim, ncol=51) ## will contain dr-model predictions 
fit <- vector("list", 3)
for(i in 1:nSim){
  fit[[1]] <- fitMod(doses, sims[i,], model="emax", S=S,
                     type="general", bnds=bnds$emax)
  fit[[2]] <- fitMod(doses, sims[i,], model="sigEmax", S=S,
                     type="general", bnds=bnds$sigEmax)
  fit[[3]] <- fitMod(doses, sims[i,], model="betaMod", S=S,
                     type="general", bnds=bnds$betaMod)
  ind <- which.min(sapply(fit, gAIC)) ## choose best model according to AIC
  pred[i,] <- predict(fit[[ind]], doseSeq=dsq, predType="ls-means")
}
qq <- apply(pred, 2, function(x) quantile(x, c(0.025,0.25,0.5,0.75,0.975)))
pp <- inv_logit(qq)

pdat <- data.table(dsq = dsq, pred = pp[3,],
                   low1 = pp[2,], high1 = pp[4,],
                   low2 = pp[1,], high2 = pp[5,])
qq <- qnorm(0.975)
pdat2 <- data.table(dose = doses, est=inv_logit(est),
                    LB = inv_logit(est - qq*sqrt(diag(S))),
                    UB = inv_logit(est + qq*sqrt(diag(S))))

qplot(dsq, pred, data=pdat, geom="line", xlab = "Dose",
      ylab="Response Probability")+
  geom_point(aes(dose, y=est), data=pdat2, alpha=0.5)+
  geom_errorbar(aes(x=dose, y=est, ymin = LB, ymax = UB),
                 data=pdat2, width=0,alpha=0.5)+
  geom_ribbon(aes(ymin = low1, ymax = high1), alpha=0.2)+
  geom_ribbon(aes(ymin = low2, ymax = high2), alpha=0.2)+
  scale_y_continuous(breaks = seq(0,1,by=0.05))+
  theme_bw()
```

## Avoiding problems with complete seperation and 0 responders

In a number of situations it makes sense to replace ML estimation for logistic regression via glm(..., family=binomial), with the Firth logistic regression (Reference: Heinze, G., & Schemper, M. (2002). A solution to the problem of separation in logistic regression. Statistics in medicine, 21(16), 2409-2419.),
implemented in logistf function from the logistf package. This is particularly important for small sample size per dose and if small number of responses are expected some or all treatment arms. Firth regression corresponds to a maximum a-posterior estimator, when using Jeffreys prior and can be shown always to exist, also in situations, where the ML estimate for logistic regression does not exist (e.g. for complete separation).

## Considerations around optimal contrasts at design stage and analysis stage

For normally distributed data, mean and variance of the mean estimate are independent. This is not the case for binary data. The analysis will be performed on the logit scale, and the estimated variance of the estimate $logit(\hat{p})$ is given by $\frac{1}{n\hat{p}(1-\hat{p})}$, where $n$ is the sample size in this dose-group (Ludger kannst Du das nachrechnen?). 

One challenge, when estimating this variance from the data and then based on that optimal contrasts (as done in the code chunks above implicitly via MCTtest) is that estimation of the variance can get imprecise for small sample size per group (e.g. smaller 20). In these situations it may make sense to just use a constant term for the variance across doses that is just $\propto$ the sample size per dose. The so calculated contrast will asymptotically not be equal to the "optimal" contrast for the underlying model, but simulations show that they can be closer to the "true" optimal contrast (calculated based on the true variance per dose group) for small sample size.

When re-running the adjusted analysis above for the optimal contrast, calculated as outlined above, we obtain an only slightly different result.
```{r}
## here we have balanced sample sizes across groups, so we select w = 1
## otherwise would select w proportional to group sample sizes
optCont <- optContr(mods, doses, w = 1)
MCTtest(doses, est, S=S, type = "general", contMat = optCont)
```


## Power and sample size considerations

```{r, eval = FALSE}
## calculate optimal contrasts (here for simplicity using the slightly suboptimal approach above)
## again assume we have balanced sample size per dose
contMat <- optContr(mods, w=1)
## use candidate models as "true scenarios" 
altModels1 <- Mods(emax = 0.25, 
                   placEff = logit(0.1), 
                   maxEff = logit(0.35)-logit(0.1),
                   doses = doses)
p1 <- 1/(1+exp(-getResp(altModels1)))
var1 <- 1/(p1*(1-p1))
altModels2 <- Mods(emax = 1, 
                   placEff = logit(0.1), 
                   maxEff = logit(0.35)-logit(0.1),
                   doses = doses)
p2 <- 1/(1+exp(-getResp(altModels2)))
var2 <- 1/(p2*(1-p2))
altModels3 <- Mods(sigEmax = c(1, 3), 
                   placEff = logit(0.1), 
                   maxEff = logit(0.35)-logit(0.1),
                   doses = doses)
p3 <- 1/(1+exp(-getResp(altModels3)))
var3 <- 1/(p3*(1-p3))
altModels4 <- Mods(sigEmax = c(2.5, 4),
                   placEff = logit(0.1), 
                   maxEff = logit(0.35)-logit(0.1),
                   doses = doses)
p4 <- 1/(1+exp(-getResp(altModels4)))
var4 <- 1/(p4*(1-p4))
altModels5 <- Mods(betaMod = c(1.1, 1.1),
                   placEff = logit(0.1), 
                   maxEff = logit(0.35)-logit(0.1),
                   doses = doses)
p5 <- 1/(1+exp(-getResp(altModels5)))
var5 <- 1/(p5*(1-p5))

func <- function(n){
  power <- numeric(5)
  power[1] <- powMCT(contMat, alpha=0.025, altModels=altModels1, S=diag(var1[,1]/n), df=Inf)
  power[2] <- powMCT(contMat, alpha=0.025, altModels=altModels2, S=diag(var2[,1]/n), df=Inf)
  power[3] <- powMCT(contMat, alpha=0.025, altModels=altModels3, S=diag(var3[,1]/n), df=Inf)
  power[4] <- powMCT(contMat, alpha=0.025, altModels=altModels4, S=diag(var4[,1]/n), df=Inf)
  power[5] <- powMCT(contMat, alpha=0.025, altModels=altModels5, S=diag(var5[,1]/n), df=Inf)
  min(power)
}

n <- seq(5,80,by=5)
pows <- sapply(n, func)
qplot(n, pows, geom="line", ylab="Min. Power over candidate set")
```

